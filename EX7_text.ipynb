{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text classification etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(sentence, pos, neg):\n",
    "    sentence = sentence.split()\n",
    "    sentence = set(sentence)\n",
    "\n",
    "    num_common_pos = len(sentence.intersection(pos))\n",
    "    num_common_neg = len(sentence.intersection(neg))\n",
    "\n",
    "    if num_common_pos > num_common_neg:\n",
    "        return \"positive\"\n",
    "    if num_common_pos < num_common_neg:\n",
    "        return \"negative\"\n",
    "    return neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi,', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"hi, how are you?\"\n",
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', ',', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x23 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of word as initial trial\n",
    "\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"hello, how are you?\",\n",
    "    \"im getting bored at home. And you? What do you think?\", \"did you know about counts\",\n",
    "    \"let's see if this works!\",\n",
    "    \"YES!!!!\"\n",
    "]\n",
    "ctv = CountVectorizer()\n",
    "ctv.fit(corpus)\n",
    "corpus_transformed = ctv.transform(corpus)\n",
    "corpus_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 9,\n",
       " 'how': 11,\n",
       " 'are': 2,\n",
       " 'you': 22,\n",
       " 'im': 13,\n",
       " 'getting': 8,\n",
       " 'bored': 4,\n",
       " 'at': 3,\n",
       " 'home': 10,\n",
       " 'and': 1,\n",
       " 'what': 19,\n",
       " 'do': 7,\n",
       " 'think': 17,\n",
       " 'did': 6,\n",
       " 'know': 14,\n",
       " 'about': 0,\n",
       " 'counts': 5,\n",
       " 'let': 15,\n",
       " 'see': 16,\n",
       " 'if': 12,\n",
       " 'this': 18,\n",
       " 'works': 20,\n",
       " 'yes': 21}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 14, ',': 2, 'how': 16, 'are': 7, 'you': 27, '?': 4, 'im': 18, 'getting': 13, 'bored': 9, 'at': 8, 'home': 15, '.': 3, 'and': 6, 'what': 24, 'do': 12, 'think': 22, 'did': 11, 'know': 19, 'about': 5, 'counts': 10, 'let': 20, \"'s\": 1, 'see': 21, 'if': 17, 'this': 23, 'works': 25, '!': 0, 'yes': 26}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import  word_tokenize\n",
    "\n",
    "ctv = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "ctv.fit(corpus)\n",
    "corpus_transformed = ctv.transform(corpus)\n",
    "print(ctv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x28 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfv.fit(corpus)\n",
    "corpus_transformed = tfv.transform(corpus)\n",
    "corpus_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_transformed.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ',', 'how', 'are', 'you', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hi', ',', 'how'),\n",
       " (',', 'how', 'are'),\n",
       " ('how', 'are', 'you'),\n",
       " ('are', 'you', '?')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import  ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "N = 3\n",
    "sentence = \"hi, how are you?\"\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "print(tokenized_sentence)\n",
    "\n",
    "n_grams = list(ngrams(tokenized_sentence, N))\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word=fishing\n",
      "stemmed_word=fish\n",
      "lemma=fishing\n",
      "word=fishes\n",
      "stemmed_word=fish\n",
      "lemma=fish\n",
      "word=fished\n",
      "stemmed_word=fish\n",
      "lemma=fished\n"
     ]
    }
   ],
   "source": [
    "# stemming and lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import  SnowballStemmer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "words = [\"fishing\", \"fishes\", \"fished\"]\n",
    "for word in words:\n",
    "    print(f\"word={word}\")\n",
    "    print(f\"stemmed_word={stemmer.stem(word)}\")\n",
    "    print(f\"lemma={lemmatizer.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply non-negative matrix factorization (NMF) or latent semantic analysis (LSA) --> singular vector decomposition (SVD)\n",
    "\n",
    "import pandas as pd \n",
    "from nltk.tokenize import  word_tokenize\n",
    "from sklearn import  decomposition\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "imdb_corpus = pd.read_csv(\"./datasets/imdb/Dataset.csv\", nrows=10000)\n",
    "imdb_corpus = imdb_corpus.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 70447)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfv.fit(imdb_corpus)\n",
    "corpus_transformed = tfv.transform(imdb_corpus)\n",
    "corpus_transformed.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components=10)\n",
    "corpus_svd = svd.fit(corpus_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70447"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "feature_scores = dict(\n",
    "    zip(\n",
    "        tfv.get_feature_names_out(),\n",
    "        corpus_svd.components_[idx]\n",
    "    )\n",
    ")\n",
    "len(feature_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'a', 'and']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "sorted(feature_scores, key=feature_scores.get, reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.split()\n",
    "    s = \" \".join(s)\n",
    "    s = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", s)\n",
    "    return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh are you kidding me'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"oh, are you kidding me?!\"\n",
    "clean_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production br br The filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically theres a family where a little boy J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Matteis Love in the Time of Money is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        clean_review  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production br br The filmin...  \n",
       "2  I thought this was a wonderful way to spend ti...  \n",
       "3  Basically theres a family where a little boy J...  \n",
       "4  Petter Matteis Love in the Time of Money is a ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_corpus = pd.read_csv(\"./datasets/imdb/Dataset.csv\", nrows=10000)\n",
    "imdb_corpus.loc[:, \"clean_review\"] = imdb_corpus.review.apply(clean_text)\n",
    "imdb_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', ',', '.', 'a', 'and']\n",
      "['br', '<', '>', '/', '-']\n",
      "['i', 'movie', '!', 'it', 'was']\n",
      "[',', '!', \"''\", '``', 'you']\n",
      "['!', 'the', \"''\", '``', '...']\n"
     ]
    }
   ],
   "source": [
    "corpus = imdb_corpus.review.values\n",
    "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfv.fit(corpus)\n",
    "corpus_transformed = tfv.transform(corpus)\n",
    "\n",
    "svd = decomposition.TruncatedSVD(n_components=10)\n",
    "corpus_svd = svd.fit(corpus_transformed)\n",
    "\n",
    "for idx in range(5):\n",
    "    feature_scores = dict(\n",
    "    zip(\n",
    "        tfv.get_feature_names_out(),\n",
    "        corpus_svd.components_[idx]\n",
    "        )\n",
    "    )\n",
    "    print(sorted(feature_scores, key=feature_scores.get, reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'and', 'of', 'to']\n",
      "['i', 'movie', 'it', 'was', 'this']\n",
      "['the', 'was', 'i', 'were', 'of']\n",
      "['her', 'was', 'she', 'i', 'he']\n",
      "['br', 'to', 'they', 'he', 'show']\n"
     ]
    }
   ],
   "source": [
    "corpus = imdb_corpus.clean_review.values\n",
    "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfv.fit(corpus)\n",
    "corpus_transformed = tfv.transform(corpus)\n",
    "\n",
    "svd = decomposition.TruncatedSVD(n_components=10)\n",
    "corpus_svd = svd.fit(corpus_transformed)\n",
    "\n",
    "for idx in range(5):\n",
    "    feature_scores = dict(\n",
    "    zip(\n",
    "        tfv.get_feature_names_out(),\n",
    "        corpus_svd.components_[idx]\n",
    "        )\n",
    "    )\n",
    "    print(sorted(feature_scores, key=feature_scores.get, reverse=True)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaamlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
